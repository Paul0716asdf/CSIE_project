{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## folder path is the parent of MEOW_Utils's path\n",
    "folder_path = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW' \n",
    "loaded_model_path = r'model42'\n",
    "loaded_opti_path = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### IF run in colab \n",
    "# from google.colab import drive \n",
    "# drive.mount('/content/drive') \n",
    "# import sys \n",
    "# sys.path.append(folder_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### IF run in kaggle\n",
    "# import sys \n",
    "# sys.path.append(folder_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEOW_Utils.SCRIPT import* \n",
    "from MEOW_Utils.Data_utils import* \n",
    "from MEOW_Utils.config import* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET TOKENIZER successfully\n",
      "SET DATASET successfully\n",
      "Per epoc round's num is 176\n",
      "Per epoc round's num is 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithoutEmbedding: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertWithoutEmbedding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertWithoutEmbedding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the model successfully\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SCRIPT_SET_TOKENIZER() \n",
    "SCRIPT_SET_QAandSUP(check_data_loader=False, path = folder_path) \n",
    "SCRIP_GET_TRAINTEST_ROUND() \n",
    "\n",
    "## if the do_mtl is True, then the model will run in multi-tasking\n",
    "## load the path's state dict \n",
    "model = SCRIPT_SET_MODEL(do_mtl=True, \n",
    "                         path = loaded_model_path, \n",
    "                         qa_optim_path = loaded_opti_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use it if you only want to change the datasize of some dataset(dataframe) \n",
    "\n",
    "# create_CoLA_df(r\"C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Dataset_infile\\CoLA_Prompt.csv\", tokenizer, data_size=CoLA_DATASIZE) \n",
    "# create_MNLI_df(r\"Dataset_infile\\MNLI.csv\", tokenizer, data_size=MNLI_DATASIZE) \n",
    "# create_SQuAD_df(r\"Dataset_infile\\SQuAD.csv\", tokenizer, data_size=10000) \n",
    "# create_QNLI_df(r\"Dataset_infile\\QNLI.csv\", tokenizer, data_size=QNLI_DATASIZE) \n",
    "# create_RTE_df(r'Dataset_infile\\RTE.csv',tokenizer,RTE_DATASIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT_TRAIN_SUPPORT(epoch_num=10)\n",
    "# SCRIPT_TRAIN_QA(epoch_num=25)\n",
    "# SCRIPT_TRAIN_BOTH_SIMU(epoch_num=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save the model parameters \n",
    "# torch.save(model.state_dict(), 'model') \n",
    "# torch.save(model.SQuAD_optimizer.state_dict(), 'qa_optimizer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### know the f1 score of the model \n",
    "# SCRIPT_EVALUATE_MODEL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Kaggle\n",
    "# #### run this and there will apper a link and point it then can download\n",
    "# %cd /kaggle/working \n",
    "# from IPython.display import FileLink \n",
    "# FileLink(r'model') \n",
    "# FileLink(r'qa_optimizer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Colab\n",
    "# from google.colab import files\n",
    "# files.download( \"/content/model1\" )\n",
    "# files.download('/content/optimizer')\n",
    "# while(1):\n",
    "#     0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 7, 15, 20, 27, 30, 33, 63, 64, 66, 67, 77, 82, 83, 86, 109, 110, 113, 122, 125, 130, 134, 140, 141, 146, 148, 157, 170, 177, 188, 197, 204, 209, 216, 217, 220, 224, 225, 228, 232, 244, 245, 252, 255, 258, 259, 262, 268, 270, 273, 279, 282, 284, 288, 292, 301, 302, 303, 311, 313, 318, 319, 322, 328, 335, 337, 341]\n"
     ]
    }
   ],
   "source": [
    "# list = SCRIPT_THE_UNANSWER_FAULT()\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 21, 26, 59, 60, 70, 90, 131, 140, 147, 151, 171, 172, 181, 184, 217, 248, 265, 277, 280, 289, 299, 324, 341, 358, 396, 437, 442, 502, 510, 571, 585, 590, 605, 637, 666, 718, 725, 732, 736, 746, 756, 765, 796, 797, 932, 948, 986, 989, 1010, 1015, 1063, 1094, 1102, 1113, 1124, 1180, 1186, 1191, 1242, 1255, 1256, 1261, 1262, 1281, 1283, 1295, 1338, 1388, 1427, 1465, 1466, 1468, 1487, 1510, 1516, 1529, 1544, 1584, 1593, 1618, 1624, 1632, 1645]\n"
     ]
    }
   ],
   "source": [
    "# list = SCRIPT_THE_ANSWER_FAULT()\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season five began on January 17, 2006. It remains the highest-rated season in the show's run so far. Two of the more prominent contestants during the Hollywood round were the Brittenum twins who were later disqualified for identity theft.\n",
      "Which season of American Idol stands out for having the highest ratings?\n",
      "correct answer is :  season five\n",
      "\n",
      "has answer probabiliy : 0.998329\n",
      "season five\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## test the question in test dataset\n",
    "\n",
    "df = SCRIPT_GET_DFHA_TEST()\n",
    "ind = 0\n",
    "context = df.iloc[ind]['context']\n",
    "question = df.iloc[ind]['question']\n",
    "EC = tokenizer.encode_plus(context, question)\n",
    "\n",
    "SEPind = [len(tokenizer.tokenize(context)) + 1]\n",
    "\n",
    "input_ids = torch.tensor([EC['input_ids']])  # 要讓他升一個維度 表示batch\n",
    "mask = torch.tensor([EC['attention_mask']])\n",
    "token = torch.tensor([EC['token_type_ids']])\n",
    "\n",
    "input_ids = input_ids.to(DEVICE)\n",
    "mask = mask.to(DEVICE)\n",
    "token = token.to(DEVICE)\n",
    "\n",
    "toks, prob = model.mt_forward(dataset_ind=DATA_IND['SQuAD'],\n",
    "                                    input_ids=input_ids,\n",
    "                                    mask=mask,\n",
    "                                    token_type_ids=token,\n",
    "                                    SEPind=SEPind,\n",
    "                                    eval=True)\n",
    "\n",
    "context = df.iloc[ind]['context']\n",
    "question = df.iloc[ind]['question']\n",
    "answer = df.iloc[ind]['text']\n",
    "\n",
    "print(context)\n",
    "print(question)\n",
    "print(\"correct answer is :\", answer)\n",
    "print(\"\")\n",
    "\n",
    "SCRIPT_ACK_QUESTION(context,question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST your question\n",
    "context = r\"\" \n",
    "\n",
    "question = \"\" \n",
    "\n",
    "SCRIPT_ACK_QUESTION(context,question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has answer probabiliy : 0.048812\n",
      "NO ANSWER\n",
      "\n",
      "has answer probabiliy : 0.200875\n",
      "NO ANSWER\n",
      "\n",
      "has answer probabiliy : 0.538285\n",
      "the kitchen\n",
      "\n",
      "has answer probabiliy : 0.658558\n",
      "the kitchen\n",
      "\n",
      "has answer probabiliy : 0.857128\n",
      "bedroom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### TEST\n",
    "context = \"Sam walks into the kitchen.\\\n",
    "Sam picks up an apple.\\\n",
    "Sam walks into the bedroom. \\\n",
    "Sam drops the apple.\" \n",
    "\n",
    "question = \"where is the lion ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)\n",
    "\n",
    "question = \"where is the banana ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)\n",
    "\n",
    "question = \"where is the fruits ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)\n",
    "\n",
    "question = \"where is the apples ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)\n",
    "\n",
    "question = \"where is the apple ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has answer probabiliy : 0.988505\n",
      "bedroom\n",
      "\n",
      "has answer probabiliy : 0.982020\n",
      "the kitchen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"where is the apple sam dropped ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)\n",
    "\n",
    "question = \"where is the apple sam picked ?\" \n",
    "SCRIPT_ACK_QUESTION(context,question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
